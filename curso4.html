<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Curso detallado sobre el uso del Template de Robótica en PacDrive. Aprende a configurar robots, modificar referencias y gestionar pantallas de visualización con nuestros vídeos y transcripciones educativas.">
    <meta name="keywords" content="curso PacDrive, template robótica, configuración robots, referencia robots, pantallas de visualización, automatización, formación PacDrive">
	<title>Portal PacDrive | Uso del Template de Robótica en PacDrive </title>
	<link rel="icon" href="/assets/icons/favicon.png" type="image/png" sizes="512x512">
	<link rel="apple-touch-icon" href="/assets/icons/apple-touch-icon-180x180.png" sizes="180x180">
	<link rel="apple-touch-icon" href="/assets/icons/apple-touch-icon-152x152.png" sizes="152x152">
	<link rel="apple-touch-icon" href="/assets/icons/apple-touch-icon-120x120.png" sizes="120x120">
	<link rel="apple-touch-icon" href="/assets/icons/apple-touch-icon-76x76.png" sizes="76x76">	
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
	<!-- Menú principal -->
    <header>
        <nav aria-label="Menú principal">
			<button id="openMenuButton" class="open-menu-button">☰</button>
            <ul>
                <li><a href="index.html">Inicio</a></li>
                <li><a href="cursos.html">Cursos</a></li>
                <li><a href="#info">Info</a></li>
            </ul>
        </nav>
    </header>
	
	<!-- Menú lateral -->
	<div id="sideMenu" class="side-menu">
		<div class="side-menu-header">	
			<h2>CONTENIDO</h2>	
			<button id="closeMenuButton" class="close-menu-button">&times;</button>
		</div>
		<div class="menu-content">
			<ul>
				<li><a href="#" onclick="showCapitulo(0)">Configurar número de robots</a></li>
				<li><a href="#" onclick="showCapitulo(1)">Configurar referencia de robots</a></li>
				<li><a href="#" onclick="showCapitulo(2)">Descripción pantallas aplicación</a></li>
				<li><a href="#" onclick="showCapitulo(3)">Simulador de ítems</a></li>
				<li><a href="#" onclick="showCapitulo(4)">Reparto de carga entre robots</a></li>
				<li><a href="#" onclick="showCapitulo(5)">Reglas de selección de ítems</a></li>
				<li><a href="#" onclick="showCapitulo(6)">Visualizador 3D</a></li>
				<li><a href="#" onclick="showCapitulo(7)">Funcionalides IoT</a></li>
				<li><a href="#" onclick="showCapitulo(8)">Ajuste trayectoria en Automático</a></li>
			</ul>
		</div>
	</div>

    <main>
		<section class="section-container">
			<!-- Titular de la sección -->
			<h1 class="section-title course-title">Uso del Template de Robótica en PacDrive</h1>
			
			<!-- Capítulo 1: Configurar número de robots -->
			<div class="capitulo-container" id="capitulo1">
				<video controls poster="assets/curso4/CambiarNumRobots.jpg" playsinline webkit-playsinline aria-label="Vídeo que muestra cómo modificar la cantidad total de robots que nuestra aplicación controlará." controlsList="nodownload">
					<source src="assets/curso4/CambiarNumRobots.mp4" type="video/mp4">
					<track src="assets/curso4/CambiarNumRobots-es.vtt" kind="subtitles" srclang="es" label="Spanish" default>
					<track src="assets/curso4/CambiarNumRobots-en.vtt" kind="subtitles" srclang="en" label="English">
					<track src="assets/curso4/CambiarNumRobots-pt.vtt" kind="subtitles" srclang="pt" label="Portuguese">
					Tu navegador no soporta la reproducción de video.
				</video>
				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En este vídeo veremos cómo modificar la cantidad total de robots que nuestra aplicación controlará. El punto de partida, como vemos, sería una situación en la que tenemos cuatro robots y deseamos bajar a dos robots. Antes de hacer el cambio, se tiene que explicar que el código asociado a cada robot, aunque estos estén desactivados, se está ejecutando y esto consume una serie de recursos. Si vamos a ver, por ejemplo, el código asociado al robot número 3, vemos que efectivamente está siendo ejecutado; hay una serie de código y una serie de recursos involucrados en el proceso.</p>
						<p>Entonces, como nuestro objetivo es eliminar los robots número 3 y 4, simplemente salimos al modo "offline", nos vamos a la carpeta "Robótica", a la subcarpeta "Control Robots" y al objeto "Lista de Variables Globales", accedemos a la constante global "Máximo Número de Robots" y simplemente hemos de modificar este cuatro por dos y, ahora, hacemos una carga con download.</p>
						<p>Cuando la carga finaliza, es importante mencionar que podría parecer más normal que estos parámetros estuvieran en el panel de configuración, puesto que lo que estamos haciendo es configurar la aplicación. Sin embargo, al final, se ha optado por ponerlos en lo que es el interior del código como constantes globales, ya que afectan de una forma muy crítica a elementos de hardware de la aplicación, que por otra parte ya conocemos durante la calificación de la máquina. Por tanto no van a cambiar durante lo que es la fase de desarrollo de lo que es la aplicación.</p>
						<p>Bien, parece que se están viendo los resultados. Ahora le damos a "play", volvemos al panel de modo automático de trabajo y vemos que efectivamente, nuestra aplicación, que inicialmente tenía cuatro robots, ahora solo representa dos. Además, si intentamos acceder al robot 3, vemos que ya no nos deja (solo tenemos dos). Y si comprobamos el código asociado al robot número 3, que hemos eliminado, vemos que efectivamente este código no se está ejecutando, por lo tanto, no existe consumo de recursos.</p>
						<p>Lo que hemos hecho es simplemente eliminar del control a los robots 3 y 4, pero no hemos modificado para nada el código de lo que es la plataforma de desarrollo Multirobot. El código sigue existiendo, solo que no se ejecuta y, por lo tanto, no consume recursos.</p>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
					<p>La plataforma de desarrollo Multirobot se encuentra preparada para trabajar con hasta 4 robots por lo que será necesario modificar su código para trabajar con el número de robots que realmente tendrá la aplicación.</p>
					<p>El número de robots a utilizar debe establecerse en tiempo de programación modificando el valor de una constante. No es posible hacerlo en tiempo de ejecución desde ninguno de los parámetros existentes en las pantallas de configuración ni tampoco desde una HMI.</p>
					<p>El código correspondiente a los robots no utilizados permanecerá intacto pero no será ejecutado por lo que no consumirá recursos del controlador</p>
				</div>	
			</div>

			<!-- Capítulo 2: Configurar referencia de robots -->
			<div class="capitulo-container" id="capitulo2" style="display:none;">
				<video controls poster="assets/curso4/CambiarReferenciaRobot.jpg" playsinline webkit-playsinline aria-label="Vídeo que muestra cómo modificar la referencia del robot seleccionado." controlsList="nodownload">
					<source src="assets/curso4/CambiarReferenciaRobot.mp4" type="video/mp4">
					<track src="assets/curso4/CambiarReferenciaRobot-es.vtt" kind="subtitles" srclang="es" label="Spanish" default>
					<track src="assets/curso4/CambiarReferenciaRobot-en.vtt" kind="subtitles" srclang="en" label="English">
					<track src="assets/curso4/CambiarReferenciaRobot-pt.vtt" kind="subtitles" srclang="pt" label="Portuguese">
					Tu navegador no soporta la reproducción de video.
				</video>
				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En este vídeo veremos cómo modificar la referencia del robot seleccionado. Tomaremos el robot número 2, que tiene un radio de trabajo determinado, y buscaremos una referencia para un robot que tenga un radio de trabajo mayor.</p>
						<p>El primer paso es seleccionar el robot que deseamos cambiar. Nos dirigimos a la sección superior y, en el selector de robots, escogemos el número 2. Como confirmación, veremos que su radio de trabajo, o su área de trabajo mejor dicho, queda resaltada en azul.</p>
						<p>Ahora nos vamos al panel de configuración. Nos aseguramos de que efectivamente el robot número 2 es el que vamos a modificar y hacemos clic en su referencia actual. En el panel que se nos abre, veremos una lista con todas las posibles referencias compatibles con la plataforma de desarrollo de aplicaciones multirrobot. Hay una serie de filtros, y uno de ellos nos indica el radio de trabajo. Vamos a escoger un radio de 800 mm. Vemos que automáticamente las referencias que no cumplen con estos filtros quedan desactivadas, y solo se activan 4 de ellas.</p>
						<p>Escogeremos aquella que más encaje con nuestras necesidades, por ejemplo, esta, que quedará automáticamente resaltada en amarillo. Esta es nuestra selección, pero aún no hemos hecho realmente el cambio. El robot activo como número 2 sigue siendo el resaltado con un trazo un poco más grueso, y el deseado es el resaltado con un fondo en amarillo.</p>
						<p>Para que este cambio tenga validez, hemos de reiniciar el controlador. Apretamos en "Reiniciar" y, tras unos breves instantes en los que la visualización quedará desactivada, el sistema se reiniciará automáticamente. Salimos del modo online, volvemos a entrar para reactivar las visualizaciones, nos vamos al robot número 2 y vemos que, efectivamente, el modelo ha sido modificado. Para confirmarlo, nos vamos al panel de modo automático y ya vemos que el radio de trabajo es mucho mayor que el que tenía antes.</p>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
					<p>Es fundamental comenzar seleccionando el robot específico (en este caso, el robot número 2) y confirmando su radio de trabajo actual. Este paso asegura que cualquier cambio se aplique al robot correcto, evitando errores en la configuración.</p>
					<p>Después de acceder a la sección de cambio de referencia del panel de configuración, es recomendable utilizar los filtros disponibles, como el radio de trabajo, para localizar una referencia que se ajuste a las necesidades específicas de la aplicación</p>
					<p>Para que los cambios tengan efecto, es necesario reiniciar el controlador. Este paso garantiza que la nueva configuración se aplique correctamente. Tras reiniciar, se debe verificar que el robot modificado tiene el nuevo radio de trabajo, confirmando así la efectividad del cambio.</p>
				</div>	
			</div>

			<!-- Capítulo 3: Descripción pantallas aplicación -->
			<div class="capitulo-container" id="capitulo3" style="display:none;">
				<video controls poster="assets/curso4/ComposicionPanelesVisualización.jpg" playsinline webkit-playsinline aria-label="Vídeo que describe la composición de las pantallas de visualización utilizadas por la aplicación." controlsList="nodownload">
					<source src="assets/curso4/ComposicionPanelesVisualización.mp4" type="video/mp4">
					<track src="assets/curso4/ComposicionPanelesVisualización-es.vtt" kind="subtitles" srclang="es" label="Spanish" default>
					<track src="assets/curso4/ComposicionPanelesVisualización-en.vtt" kind="subtitles" srclang="en" label="English">
					<track src="assets/curso4/ComposicionPanelesVisualización-pt.vtt" kind="subtitles" srclang="pt" label="Portuguese">
					Tu navegador no soporta la reproducción de video.
				</video>
				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En este vídeo se describirá la composición de las pantallas de visualización utilizadas por la aplicación. Para acceder a ellas, haremos doble clic en "Vis_principal" o bien, si no estamos utilizando el entorno de desarrollo, utilizaremos un navegador web y la dirección HTTP, IP del controlador, puerto 8080, y el nombre de la página “webvisu.htm".</p>
						<p>Una pantalla de visualización se compone de cuatro sectores:</p>
						<ol>
							<li><strong>Sector superior:</strong> Aquí se podrá escoger el robot sobre el que se desea interactuar. Después también tiene una serie de botones para solicitar la entrada a un modo de trabajo u otro, unos pilotos que nos indican el modo de trabajo activo, las coordenadas cartesianas del robot, el ángulo del eje auxiliar de giro (si es que el robot lo posee) sistema de coordenadas activo y ciclos por minuto de este robot.</li>
							<li>
								<p><strong>Sección izquierda:</strong> Tendremos lo que es la botonera para navegar a través de todos los paneles que incluye la aplicación. El panel por defecto es "Configuración", a través del cual podemos darle valores a una serie de parámetros que nos permitirán configurar el comportamiento general de la aplicación.</p> 
								<p>A través del botón "Automático", entraremos al panel donde se nos mostrará información relativa al modo de trabajo automático, del mismo modo que ocurre con los botones "Aprendizaje" y "Impulsos". </p>
								<p>Con el botón de "Recetas", accederemos a un panel específico general para hacer lo que es la gestión de recetas (cargar, editar, borrar recetas) y también para configurar todos los parámetros de la aplicación a su valor por defecto. </p>
								<p>En el panel de "Alarmas", tendríamos una visión de las 10 alarmas activas en ese momento y un resumen de la situación de cada uno de los robots utilizados.</p>
								<p>Finalmente, tenemos acceso a una serie de paneles específicos que vienen en el template utilizado para construir la plataforma de desarrollo de aplicaciones multi-robot. Estos paneles de visualización se han dejado tal cual, pues pueden ser útiles en caso de que se amplíe la aplicación. Para regresar a los paneles de visualización, iremos a "Vis_Navigation" y daremos "Ir Aplicación".</p>
								<p>Finalmente, podemos escoger el idioma de los paneles de visualización a través de una serie de banderitas: español, inglés y portugués.</p>
							</li>	
							<li><strong>Sector central:</strong> El panel central va cambiando en función del botón que tengamos pulsado en cada momento.</li>
							<li><strong>Sector derecho:</strong> Este sector mostrará la información de los elementos de hardware del controlador, es decir, entradas y salidas digitales, o las entradas de emergencia. En el caso específico de que estemos visualizando el panel de "Automático", veremos además el contenido de los registros de desplazamiento para la cinta de recogida y de entrega.</li>							
						</ol>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
					<p>Es posible acceder a las pantallas de visualización desde el entorno de desarrollo haciendo doble clic en "Vis_principal" o utilizando un navegador web utilizando la dirección http://ip controlador:8080/webvisu.htm”.</p>
					<p>Las pantallas de visualización se dividen en cuatro sectores: uno superior para ordenar el modo de trabajo y seleccionar el robot sobre el que se desea interactuar, uno lateral izquierdo para seleccionar qué información queremos mostrar en el panel central, uno central con información y parámetros relativos a un modo de trabajo determinado (según lo seleccionado en el sector izquierdo) y uno lateral derecho para visualizar el estado de las entradas/salidas del controlador o el contenido de los registros de desplazamiento de las cintas de recogida y entrega.</p>
					<p>Es posible escoger el idioma de las pantallas de visualización entre tres opcione (español, inglés y portugués).</p>
				</div>	
			</div>
			
			
			<!-- Capítulo 4: Simulador de ítems -->
			<div class="capitulo-container" id="capitulo4" style="display:none;">
				<iframe 
					src="https://www.youtube.com/embed/IGlXcWXshPI?rel=0" 
					frameborder="0" 
					allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
					allowfullscreen 
					aria-label="Vídeo que describe el apartado de simulación de ítems incluido en la aplicación"> 
				</iframe>
			
				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En este vídeo se describirá el simulador de ítems integrado en la plataforma para conocer sus opciones. Nos dirigiremos al panel de configuración y a la sección donde se encuentran los parámetros relativos a la captura y simulación de ítems.</p>
						<p>Los primeros parámetros a tener en cuenta corresponden con las dimensiones del propio ítem, que pueden ser distintas según pertenezca a la cinta de recogida o a la de entrega, y el número de ítems a generar en cada disparo. También es importante el modo de trabajo del propio simulador, que puede ser continuo, es decir, que el disparo se produzca de forma automática cada cierto avance de la cinta, o modo no continuo, donde el propio usuario es quien genera el disparo cuando lo estime oportuno.</p>
						<p>Con estos parámetros vamos a ver el funcionamiento del simulador. Si nos vamos al panel automático en la sección inferior, vemos que existen dos botones: "crear ítem bueno" y "crear ítem malo". Si creamos un ítem bueno, veremos que este aparece en el cero de coordenadas de la cinta de recogida a la cual pertenece. Todos los ítems se crean respecto al cero de coordenadas de la cinta a la cual pertenecen. En este caso, en este eje de coordenadas, vamos a arrancar la cinta uno y también vamos a arrancar la cinta dos para que se vayan evacuando los productos. Este ítem, al ser creado como bueno, se considera válido para ser procesado por el robot. Por tanto, el robot, cuando se encuentra en la zona de trabajo, en la zona verde, lo va a buscar. Un ítem malo no es procesable por el robot, por tanto, el robot lo dejará pasar. Que un ítem sea bueno o malo es labor de la cámara de visión artificial, según los criterios que se definan para la aplicación.</p>
						<p>Bien, vamos a repetir la operación, pero en este caso, en cada disparo vamos a generar tres ítems. Si repetimos la operación, vemos que los tres ítems se han generado, como se ha comentado anteriormente, en el cero de coordenadas de la cinta de recogida, es decir, uno encima del otro. Esto es una situación que habitualmente no se suele dar en la vida real y no es, por lo general, deseable.</p>
						<p>Por tanto, se han añadido una serie de parámetros que permiten generar ítems alrededor del cero de coordenadas con una cierta variabilidad, tanto en X como en la coordenada Y, e incluso en el ángulo. Por ejemplo, vamos a probar añadiendo una variabilidad de 200 alrededor del cero del eje coordenado X, lo cual quiere decir que cada ítem adoptará una X aleatoria entre estos dos rangos. La Y también tendrá su variabilidad, y aprovecharemos para darle incluso también un ángulo al ítem, un ángulo alrededor del eje Z entre -45º y +45º de forma aleatoria.</p>
						<p>Vamos a probar y vamos generando disparos de forma manual. Vemos que los ítems ya no se superponen y circulan con una cierta separación entre ellos. Aquí se ve más claramente, asimilándose más a lo que nos podríamos encontrar en la vida real.</p>
						<p>Bien, ahora vamos a probar el modo continuo. Si lo activamos, veremos que cada 200 mm de avance de cinta se genera un pulso de duración 100 milisegundos que desemboca en la generación de tres ítems sobre la cinta de recogida con esta variabilidad en sus coordenadas. Vamos a verlo. Sí, bien, aquí los vamos teniendo. Si nos fijamos, los ítems se van generando muy aleatoriamente, con una densidad más o menos elevada, pero algunos de ellos se pueden encontrar superpuestos. Por ejemplo, aquí estos dos están superpuestos, o aquí vemos también un grupo de ellos que están superpuestos. Esto hay aplicaciones, sobre todo de clasificación, en los que puede ser habitual encontrarlo, aunque no es algo que se suela buscar, porque luego las coordenadas Z también son importantes.</p>
						<p>En estos casos, a veces para simular una llegada de material más realista, lo que se suele hacer es falsear o jugar, mejor dicho, con estos parámetros para que los ítems se generen con cierta aleatoriedad y cierta densidad, pero que nunca se superpongan los unos a los otros. Lo recomendable sería, en estos casos, que el disparo no corresponda con el campo de visión de la cámara, como tendría que ser lo habitual, sino que sea un pelín superior al propio ancho del ítem y además generar solamente un ítem por cada disparo.</p>
						<p>Por ejemplo, si activamos aquí un ítem por cada disparo y avance, es decir, el disparo cada 100 mm de avance de cinta, que es un pelín superior a 80, obtendríamos. Vemos que aún no lo hemos conseguido porque aún se siguen superponiendo, pero se estaría generando un ítem cada 100 mm de avance de cinta. El problema aquí es que, como sigue existiendo una cierta variabilidad alrededor de la coordenada X, el ítem de una foto puede superponerse al de la foto anterior. En este caso, para evitarlo, simplemente vamos a configurarlo en cero la variabilidad alrededor de la X.</p>
						<p>En este caso ya vemos que la Y sigue siendo aleatoria. La X siempre se genera en el cero, pero al estar separado 100 mm con respecto a la anterior foto y la siguiente, ya nunca se pisan. Podríamos conseguir, por ejemplo, en aplicaciones en las que el producto venga en fila india y distante entre sí, pues este efecto. Cogeríamos la Y, la variabilidad alrededor del eje Y se lo bajaríamos a cero, volveríamos y aquí veríamos cómo los ítems vienen distantes entre sí. Aunque no aparentemente no parezcan hacerlo debido al ángulo, la separación entre los centros de los ítems es equidistante, igual a 100 o a 200. Para verlo más claramente, podemos eliminar el ángulo alrededor del eje Z y aquí lo veríamos. Aquí ya vemos claramente que los ítems se generan equidistantes entre sí y vienen por la cinta de recogida en fila india. Hay aplicaciones en las que es así y que puede servir este simulador. Podemos separarlos un poco más, 200, y así simular una situación de una aplicación real de una forma más cómoda.</p>
						<p>Muy bien. Además, para ajustar finamente, porque el simulador, si nos fijamos, el robot va a buscar el producto justo en el centro del ítem. Pero hay aplicaciones en las que esto no es así. Para ajustar un poco más el trabajo de captura de ítems, tenemos los offsets, que dependen o son distintos para cada robot.</p>
						<p>En este caso, como el ancho del ítem no son 80, si aplicamos un offset de 40 positivos en la X, veremos cómo el robot ya no lo coge en el centro, sino que lo coge justo en el borde. Esto sería con 40 positivos. Con 40 negativos, lo haría en el otro extremo. Esto puede ayudar cuando se utiliza una cámara de visión artificial real a ajustar pequeños desajustes que tenga el robot con respecto a esta cámara. Un robot en concreto puede ser que un robot tenga siempre un error conocido de 2 mm o de 3 mm respecto a la X o respecto a la Y, y el siguiente robot pues no los tenga. Mediante estos parámetros podemos ajustar cada robot de forma que su herramienta se ponga encima del producto de la misma forma en todos los robots.</p>
						<p>Bien, otra cosa que hay que decir antes de acabar sería que el simulador de ítems se superpone al trabajo de una cámara de visión artificial real. Esto quiere decir que si en este momento tuviéramos una cámara de visión artificial leyendo objetos reales, estos serían dados de alta encima de la cinta de recogida, superponiéndose a los que están de alta virtualmente a través del simulador. Por esto es recomendable, cuando se utiliza una cámara de visión artificial real leyendo producto real, no utilizar el simulador.</p>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
						<p><strong>Modos de Generación de Ítems:</strong> El simulador puede generar ítems de dos maneras: manualmente, generando items individuales dentro del campo de visión del robot de forma manual, o de forma continua, generando items automáticamente a lo largo del tiempo a intervalos predefinidos . Esta flexibilidad en la generación permite una variedad de pruebas y simulaciones para evaluar el rendimiento del robot en diferentes condiciones operativas.</p>
						<p><strong>Ajustes de Variabilidad:</strong> Los parámetros de variabilidad que se pueden ajustar incluyen las coordenadas X e Y y el ángulo de los ítems. Esto permite simular una amplia gama de posiciones y orientaciones, replicando de manera más realista las condiciones en las que el robot debe operar, haciendo posible evaluar cómo el sistema responde ante diferentes escenarios de colocación y orientación de ítems.</p>
						<p><strong>Prevención de Superposición de Ítems:</strong> El sistema tiene mecanismos para evitar que los ítems se generen superpuestos unos encima de los otros, asegurando que cada ítem se ubique en una posición única y no interfiera con ítems vecinos. Esto es crucial para mantener la precisión en la detección y manipulación de los ítems por parte del robot y para evitar errores en las pruebas y simulaciones.</p>
						<p><strong>Ajuste de Offsets:</strong> Los offsets se utilizan para ajustar la posición de captura del ítem, permitiendo corregir cualquier desajuste entre el robot y la cámara de visión artificial. Estos ajustes son necesarios para asegurar que el robot pueda identificar y manipular los ítems correctamente, especialmente si hay variaciones en la alineación entre los diferentes componentes del sistema.</p>
						<p><strong>Interacción con la Cámara de Visión Real:</strong> Aunque el simulador puede trabajar en conjunto con una cámara de visión real para pruebas más precisas, se recomienda evitar el uso simultáneo de ambos sistemas para prevenir posibles conflictos. Utilizar solo uno de los sistemas a la vez ayuda a garantizar que el funcionamiento del simulador sea más eficiente y que las pruebas no se vean afectadas por interferencias entre los sistemas.</p>
				</div>	
			</div>
			
			<!-- Capítulo 5: Reparto de carga entre robots -->
			<div class="capitulo-container" id="capitulo5" style="display:none;">
				<iframe 
					src="https://www.youtube.com/embed/xk3Bc-ihg20?rel=0" 
					frameborder="0" 
					allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
					allowfullscreen 
					aria-label="Vídeo que describe las opciones de reparto de carga entre robots utilizadas por la aplicación."> 
				</iframe>

				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En este vídeo veremos las opciones de reparto de carga entre robots incluidas en la aplicación. Para ello, nos dirigiremos al panel de configuración y a la sección donde se encuentran los parámetros relativos al modo automático de trabajo.</p>
						<p>En este panel, vemos que, en cuanto a reparto de carga, existen tres posibilidades: no utilizar ningún reparto de carga, utilizar un reparto de carga basado en la zona de la cinta donde se encuentra el ítem, o bien un reparto de carga basado en la categoría que la cámara asigna a cada ítem.</p>
						<p>Para comprobar el comportamiento de la máquina ante cada una de estas tres posibilidades, nos aseguraremos de que los cuatro robots que vamos a emplear en el proceso poseen el mismo tipo de reparto de carga. En este caso, seleccionaremos “ninguno”. Nos dirigiremos al panel automático y arrancaremos las cintas en esta modalidad.</p>
						<p>Como no existe ningún reparto de carga, cada robot intentará procesar todos los ítems que entren en su zona de influencia. Aquellos que no consiga procesar seguirán su camino hasta alcanzar la zona de influencia del siguiente robot, que hará lo propio, y así hasta el último de los robots.</p>
						<p>A simple vista, vemos que los primeros robots están asumiendo la mayor parte de la carga de trabajo, mientras que los últimos robots tienden a asumir una carga mucho menor. El robot número uno y el número dos están continuamente procesando ítems sin parar, mientras que el robot número tres está procesando ítems solamente el 50% de su tiempo, más o menos, y el cuarto robot no procesó ninguno; no hay ningún ítem que alcance su zona de influencia.</p>
						<p>Esto puede tener consecuencias negativas en cuanto a mantenimiento porque, evidentemente, los robots que más trabajan se desgastan antes y necesitan más planes de mantenimiento que los últimos. Por tanto, es muy probable que a lo largo del año se produzcan muchas más paradas técnicas que si el reparto estuviera más equilibrado. Luego, los planes de mantenimiento predictivo y preventivo podrían complicarse porque necesitarían considerar no la máquina como un conjunto, sino cada uno de los robots como si fueran máquinas individuales.</p>
						<p>Bien, vamos a ver el comportamiento del sistema con otro reparto de carga. Nos dirigiremos al panel de configuración y, en este caso, seleccionaremos un reparto de carga “zonal” en cada uno de los cuatro robots.</p>
						<p>En este tipo de reparto de carga, lo que se hace es dividir el ancho de la cinta de recogida en tantas zonas como robots se encuentren activos, es decir, en automático y trabajando. En este caso, como tenemos cuatro robots, el ancho de la cinta se divide en cuatro secciones, cada una con el 25% del ancho total de la cinta.</p>
						<p>De tal modo que los ítems que circulan por el primer 25% del ancho de la cinta serán asignados al primer robot. El segundo robot recogerá solamente los ítems que se encuentren dentro del siguiente 25%. El tercer robot solo recogerá los ítems que se encuentren en el tercer 25%, y el cuarto robot hará lo propio con los ítems que se encuentren en el último 25%.</p>
						<p>De esta forma, ya vemos que el reparto está más equilibrado. Tal vez los primeros robots estén produciendo menos tiempo, pero eso es porque el reparto está más equilibrado y los últimos dos robots están produciendo más que antes, cuando no teníamos ningún reparto de carga.</p>
						<p>Si ahora, por ejemplo, cogiéramos el robot número dos y lo inhibiéramos, el sistema se auto-configuraría y las zonas se dividirían no en cuatro, sino en tres, puesto que solamente tendríamos tres robots en automático y produciendo. El primer robot recogerá solamente los ítems que se encuentren en el primer tercio del ancho de la cinta. El segundo no recogerá ninguno porque está inhibido. El tercer robot recogerá solamente los ítems que se encuentren en la parte central de la cinta, en el segundo tercio, y el cuarto robot recogerá solamente los ítems que se encuentren en el último tercio de la cinta, el último 33%.</p>																								
						<p>Esto puede ser útil en aquellos casos en los que, por avería o por otras causas, se deba detener uno de los robots y necesitemos que el resto sigan produciendo. Se podría bajar la velocidad de la cinta y los tres robots supervivientes asumirían la totalidad de la carga.</p>
						<p>Bien, vamos a parar las cintas y, en este caso, vamos a seleccionar el último tipo de reparto de carga existente, que sería el reparto de carga basado en la categoría que la cámara asigna a cada ítem.</p>						
						<p>Haremos lo mismo: nos dirigiremos al robot 1, cámara; robot 2, cámara, y así sucesivamente. En este caso, la cámara asignará una categoría a cada ítem en función de sus características. El operario podrá asignar cada una de estas categorías para ser procesadas por un robot u otro.</p>						
						<p>En este ejemplo, vamos a dividir la carga de forma equilibrada y asignaremos la categoría 0 al robot 1, la categoría 1 al robot 2, la categoría 2 al robot 3 y la categoría 3 al robot 4. La cuarta categoría se la asignaremos a todos los robots, de forma que si hay un ítem que tenga categoría 4, será procesado por cualquiera de los robots.</p>						
						<p>Vamos a aceptar, nos vamos al panel automático y vamos a borrar la cinta para que no nos cree confusión. El segundo robot, que está inhibido, lo vamos a habilitar y ahora vamos a arrancar la cinta de nuevo. Dado que el generador de ítems está generando ítems de forma aleatoria, las categorías también son aleatorias. Por tanto, es muy probable que la distribución sea bastante equitativa.</p>						
						<p>Vemos que el robot número uno solamente está cogiendo ítems que hayan sido clasificados como categoría 0 o categoría 4. El robot número 2 solo recogerá los de categoría 1 y 4; el robot número 3 recogerá los de categoría 2 y 4; y el cuarto robot los de categoría 3 o 4. Algunos ítems pueden escapar, por ejemplo, si algún ítem de categoría 0 no ha sido procesado por el primer robot, ya no será procesado por ninguno y se escapará. Los ítems de categoría 4 es menos probable que se escapen porque, si no fueran procesados por el robot 1, aún podrían ser procesados por el 2, por el 3 o por el 4. Hemos visto que se ha escapado uno.</p>						
						<p>Para evitar esto, siempre que la aplicación lo permita, es posible utilizar repartos de carga distintos para cada robot. Lo habitual es que el cuarto robot intente procesar todo lo que el resto de robots no pueda procesar. Para eso, se puede dirigir al panel de configuración y para el cuarto robot solamente indicar que no deseamos ningún reparto de carga. En este caso, el robot número 4 procesará todos los ítems que lleguen a su zona de influencia, siempre y cuando pueda, claro. Esto no todas las aplicaciones lo permiten.</p>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
					<p><strong>Tipos de Reparto de Carga:</strong></p>
					<ul>
						<li><strong>Sin Reparto de Carga:</strong> Los robots intentan procesar todos los ítems en su zona de influencia. Esto puede resultar en una distribución desigual de la carga de trabajo, con los primeros robots procesando más ítems que los últimos, lo que puede afectar el mantenimiento y la eficiencia operativa.</li>
						<li><strong>Reparto de Carga Zonal:</strong> Se divide el ancho de la cinta en zonas específicas para cada robot. Esto equilibra la carga de trabajo y el desgaste en los robots mejorando la eficiencia global. Si un robot se inhibe, el sistema ajusta automáticamente el reparto entre los restantes, asegurando continuidad en la producción.</li>
						<li><strong>Reparto Basado en Categorías:</strong> Los ítems son clasificados en categorías por la cámara, y cada robot está asignado a procesar ciertas categorías. Esto permite una distribución específica y controlada de los ítems, optimizando el procesamiento al asegurar que cada robot maneje los ítems que mejor se ajusten a sus capacidades.</li>
					</ul>
					<p><strong>Flexibilidad del reparto de Carga:</strong></p>
					<ul>
						<li><strong>Adaptabilidad:</strong> El sistema puede ajustar el reparto de carga automáticamente si uno de los robots se inhibe, redistribuyendo el trabajo entre los restantes para mantener la producción. Esto asegura que la operación continúe sin interrupciones significativas, adaptándose a cambios en la disponibilidad de los robots.</li>
						<li><strong>Multiconfiguración:</strong> Es posible configurar cada robot con un tipo específico de reparto de carga. Por ejemplo, algunos robots pueden estar configurados para procesar todos los ítems que los otros robots no pueden manejar, mientras que otros pueden estar asignados a procesar ítems según categorías o zonas específicas. Esta flexibilidad asegura una cobertura completa y minimiza el riesgo de que algunos ítems no sean procesados adecuadamente.</li>
					</ul>
				</div>	
			</div>
			
			<!-- Capítulo 6: Reglas de selección de ítems -->
			<div class="capitulo-container" id="capitulo6" style="display:none;">
				<iframe 
					src="https://www.youtube.com/embed/XkIW-Sa0lVw?rel=0" 
					frameborder="0" 
					allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
					allowfullscreen 
					aria-label="Vídeo que describe las opciones de selección de ítems incluidas en la aplicación."> 
				</iframe>

				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En este vídeo se verá cómo funciona el selector de objetivos del modo automático de trabajo. En una situación real, es muy probable que en el área de trabajo del robot, esta área de color verde, se encuentren varios ítems a procesar. De alguna manera, se le ha de decir al robot cuál de estos ítems debe ser el primero. Para ello, se utiliza una serie de reglas. Las reglas que incluye la plataforma de desarrollo de aplicaciones multirobot son tres y se pueden encontrar en el panel de configuración, en la sección de parámetros del modo automático. En esta sección, en esta zona, tenemos tres para la cinta de recogida o operación de picking y los mismos tres para la cinta de entrega o operación de place. Vamos a ver un ejemplo de cada, que es como mejor se entiende.</p>
						<p>Primero seleccionaremos para el robot número 1 la regla de selección “cercana”. Volvemos al panel automático y vamos a desinhibir el robot para que empiece a procesar los ítems que se encuentran dentro de su área de trabajo. Como la regla de selección es la “cercana”, lo que va a hacer es buscar el ítem que se encuentre más cerca del cero de coordenadas del robot, que estaría marcado por estos ejes cartesianos. En este caso, debería ser el 4, pero el 4, si nos fijamos, está marcado en gris.</p>
						<p>¿Esto por qué es? Porque este ítem ha sido marcado para no ser procesado debido a que se encuentra más allá de los límites software de este robot. Los límites software, si los vamos a... hacemos una rápida visita, se encuentran aquí. Para este robot 1, el robot 2 tiene otros límites distintos; están fijados en -400. Así que es muy probable que este ítem, el 4, tenga una cota inferior a -400 y, por tanto, no debe ser procesado. Entonces vamos a darle al botón inhibir para habilitar el robot y vamos a ver lo que hace. Vemos que se va al 5 porque su cero de coordenadas es el más cercano al cero del robot, luego al 3, luego seguramente al 2, al 7, siempre está escogiendo aquel cuyo centro se encuentre más cercano al centro de coordenadas del robot, hasta quedarse sin candidatos viables.</p>
						<p>Bien, vamos a inhibir el robot para que no trabaje y hacemos llegar más ítems al área de trabajo del robot. Por ejemplo, aquí fijémonos que estos siete ítems, que estaban marcados como inviables para el robot número uno porque su cota Y está más abajo del límite inferior Y, han quedado desmarcados al rebasar la zona de trabajo del robot número 1. Esto es así porque el robot número 2 debe tener otros límites software. Por tanto, lo que no era válido para el robot uno no tiene por qué ser también inválido para el robot número dos.</p>
						<p>Entonces, volviendo a lo que estábamos haciendo, volvemos al panel de configuración y en este caso seleccionamos otra regla: la “lejano negativa”. Lejano negativa quiere decir que el robot escogerá aquel ítem cuyo cero de coordenadas se encuentre más lejos del cero de coordenadas del robot, pero en sentido negativo respecto al eje cartesiano X. En este caso, muy probablemente será el 1. Vamos a verlo. Exacto. Luego, el siguiente que va a procesar será el 13 porque es el siguiente viable más lejano en negativo y así el 8, dependiendo si está dentro o fuera del área verde, pues lo procesará o no. En este caso, está fuera por un pelín, no lo procesa.</p>
						<p>Vamos a inhibir y hacemos llegar más ítems al área de trabajo. Bueno, ya tenemos unos cuantos y vamos a seleccionar la última de las reglas que nos faltaba por probar: la “lejana positiva”, que es exactamente igual a lo que hemos visto hasta ahora, pero cogerá el ítem cuyo centro se encuentre más lejos del cero de coordenadas del robot, pero en sentido positivo. Es decir, en este caso sería el 2. Vamos a habilitar el robot y así... ahora será el 3.</p>
						<p>No hay una regla de selección mejor que otra; depende de la aplicación y lo que se pretende de ella. En este caso se incluyen estas tres porque son las más evidentes, pero corresponde al desarrollador de la máquina decidir cuál es la más correcta para su máquina y, sin ninguna de ellas, desarrollar la suya propia.</p>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>

					<p><strong>Selección de Ítems Basada en Reglas:</strong> La plataforma de desarrollo de aplicaciones multirobot permite seleccionar ítems para el procesamiento mediante reglas específicas. Estas reglas, como “cercana”, “lejano negativa” y “lejana positiva”, ayudan a determinar cuál ítem debe ser procesado primero, basándose en su proximidad al centro de coordenadas del robot o en su distancia en sentido positivo o negativo.</p>
					<p><strong>Importancia de los Límites Software:</strong> Los límites software del robot juegan un papel crucial en la selección de ítems. Los ítems que se encuentran fuera de los límites software del robot no son procesados. Estos límites pueden variar entre diferentes robots, por lo que un ítem puede ser válido para un robot y no para otro.</p>
					<p><strong>Adaptabilidad a Diferentes Reglas de Selección:</strong> La elección de la regla de selección más adecuada depende de la aplicación específica y de los objetivos del proceso. No hay una regla de selección universalmente mejor; en su lugar, se deben adaptar las reglas según los requisitos de la tarea y las características del entorno de trabajo.</p>

				</div>	
			</div>
			
			<!-- Capítulo 7: Visualización 3D -->
			<div class="capitulo-container" id="capitulo7" style="display:none;">
				<iframe 
					src="https://www.youtube.com/embed/zqw2l6VHdgs?rel=0" 
					frameborder="0" 
					allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
					allowfullscreen 
					aria-label="Vídeo que describe las posibilidades del visualizador 3D utilizado conjuntamente con la aplicación."> 
				</iframe>

				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En este vídeo veremos cómo podemos representar en tres dimensiones el comportamiento de una máquina creada con la plataforma de desarrollo de aplicaciones multirobot. Para ello, se hace uso de un aplicativo externo llamado Smartvisu, que se basa en Unity3D y que no necesita ser instalado; es autoejecutable.</p>
						<p>La plataforma de desarrollo de aplicaciones multirobot, en su panel de configuración, incluye un botón llamado "Visualización 3D" que, una vez activado, enviará a dicho programa externo, mediante comunicaciones Ethernet UDP, toda una serie de datos que permitirán crear en 3D la configuración actual de la máquina.</p>
						<p>Vamos a ver el aspecto de este programa externo, Smartvisu. Vemos que en su pantalla de presentación solo necesita un dato: la IP del controlador. Este aplicativo externo, de momento, solo es compatible con una serie reducida de robots, todos de Schneider Electric. Básicamente, son los robots tipo Scara, los tipo Delta de la serie T, que solo tienen dos brazos, y los tipo Delta de la serie P, que tienen tres brazos y además están incluidos en la plataforma de desarrollo de aplicaciones multirobot.</p>
						<p>Además, es posible utilizar una serie de objetos geométricos para representar, por ejemplo, ítems, cajas u otros elementos, y también cintas. Bien, le damos a conectar y vemos que enseguida nos aparece el estado actual de configuración de nuestra máquina, tal como hayamos definido en la plataforma de desarrollo de aplicaciones multirobot.</p>
						<p>Por supuesto, podemos con el ratón hacer zoom, quitarlo, rotarlo, verlo en todos los ángulos. Además, aquí tenemos un atajo en tres dimensiones para poder verlo desde distintos puntos de vista, aunque con el ratón es mucho más cómodo. Luego, si pulsamos y mantenemos pulsado el botón control y hacemos clic sobre cada uno de los robots, nos aparecerá información adicional de cada uno de ellos.</p>
						<p>Vamos a apartarlo un poco. ¿Qué información adicional? Básicamente, la referencia del robot, si tiene o no tiene eje de giro (todos ellos lo tienen de momento), y las coordenadas cartesianas de su TCP (centro de coordenadas de la herramienta).</p>
						<p>También podemos optar por ver el espacio de trabajo de cada uno de los robots o configurar el segundo o la trayectoria seguida por el TCP. Vamos a hacerlo un poquito más grande.</p>
						<p>Bien, si volvemos a la aplicación y cogemos los dos robots que vamos a utilizar para esta demostración y los habilitamos para funcionar, vamos a darle marcha a las cintas. Si volvemos a la pantalla 3D del programa externo, aquí vemos el funcionamiento de la visualización 3D, que como vemos está siguiendo perfectamente lo que está haciendo la máquina.</p>
						<p>Aquí, si nos fijamos, vemos la trayectoria marcada para el robot número dos; el uno también se la podemos marcar. Esto es una herramienta muy potente, sobre todo en las fases de desarrollo de la aplicación, cuando aún no tenemos disponible un robot físicamente o, aún teniéndolo, no nos interesa probar con el robot para evitar impactos o porque no estamos seguros de si algún algoritmo está bien depurado o puede ser un riesgo probarlo con el robot físicamente.</p>
						<p>En tales casos, siempre se recomienda trabajar con los ejes en modo virtual y utilizar esta herramienta porque nos da una flexibilidad bastante elevada, incluso en la selección de algunos de los parámetros. Por ejemplo, para ver si el reparto de cargas es correcto o si va a dar de sí. Unida con el simulador de ítems, esta herramienta puede ayudarnos a ver si la máquina, cuando conectemos este programa en la máquina real, va a ser correcto o no.</p>
						<p>La última cosa que hay que decir es que, una vez activado el botón de visualización, ya no pueden existir más cambios. El mundo 3D ya ha sido creado y ha sido definido y no puede ser redefinido. Es decir, si queremos utilizar ítems con unas dimensiones distintas, ya no lo podríamos hacer. Tendríamos que apagar el controlador y volver a encenderlo. Entonces, al volver a activar el botón "Visualización 3D", estos cambios quedarían reflejados.</p>
						<p>Por ejemplo, si vamos aquí a ítems y hacemos que el ítem sea más grande, este cambio que hemos hecho y que debería haberse reflejado en las características o dimensiones del objeto gráfico en 3D, vemos que no hay cambio alguno porque ya se han mandado estos datos al inicio.</p>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
					<p><strong>Uso de Smartvisu para Visualización 3D:</strong> La plataforma de desarrollo de aplicaciones multirobot permite representar el comportamiento de la máquina en un entorno tridimensional utilizando para ello la aplicación externa Smartvisu. Esta aplicación basada en Unity3D es autoejecutable y no necesidad instalación es capaz de recibir datos mediante comunicaciones Ethernet UDP para crear una representación 3D precisa de la configuración de la máquina.</p>
					<p><strong>Compatibilidad y Funcionalidades de Smartvisu:</strong> Smartvisu es compatible con varias gamas de robots de Schneider Electric como las DeltaP o DeltaT. Permite visualizar el estado actual de la máquina, realizar ajustes de vista en 3D, y obtener información adicional sobre los robots, como su referencia, su espacio de trabajo o las coordenadas cartesianas del TCP (centro de coordenadas de la herramienta).</p>
					<p><strong>Ventajas en el Desarrollo y Simulación:</strong> La visualización 3D es especialmente útil durante el desarrollo de aplicaciones, permitiendo verificar la trayectoria y el funcionamiento de los robots sin necesidad de un robot físico. Esto facilita la identificación de problemas y la validación de algoritmos en un entorno virtual antes de realizar pruebas físicas.</p>
					<p><strong>Limitaciones:</strong> Una vez activada la visualización 3D, los datos no pueden modificarse hasta que el controlador sea reiniciado. Los cambios en dimensiones o características de los ítems no se reflejarán en la visualización 3D sin reiniciar el sistema, por lo que es importante planificar y verificar los datos antes de activar la visualización.</p>
				</div>	
			</div>

			<!-- Capítulo 8: Funcionalidades IoT -->
			<div class="capitulo-container" id="capitulo8" style="display:none;">
				<iframe 
					src="https://www.youtube.com/embed/p4CCfO8_dn8?rel=0" 
					frameborder="0" 
					allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
					allowfullscreen 
					aria-label="Vídeo que describe las posibilidades de conexión de la aplicación con un software basado en nube."> 
				</iframe>

				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>
					<div class="transcripcion-content">
						<p>En el presente vídeo hablaremos de las funcionalidades IoT incluidas en la plataforma de desarrollo de aplicaciones multirobot. Quizás la parte más complicada sea definir para qué vamos a utilizar estas funcionalidades. ¿Las vamos a utilizar para, por ejemplo, mejorar la productividad de la máquina? ¿O para crear un plan más eficiente de mantenimiento? ¿O nuestra intención es crear un nuevo modelo de negocio basado en la servitización?</p>
						<p>En función del objetivo final perseguido, necesitaremos extraer una serie de información de nuestra máquina. Y, en función de este tipo de información, necesitaremos acceder a ciertos datos de ella. Por ejemplo, uno de los datos que podemos encontrar en el panel de configuración es las maniobras OK. Con las maniobras OK podemos crear, por ejemplo, un plan de mantenimiento eficaz. Claramente, no. Por ejemplo, si nuestra intención es cambiar una junta cada 20,000 maniobras, el que hayamos hecho 15,000 maniobras OK no quiere decir que hayamos hecho, por ejemplo, 6,000 que no estén OK. Entonces, este dato por sí mismo, aunque podría llegar a ser utilizado, es insuficiente para hacer algún tipo de plan de mantenimiento que sea mínimamente eficaz. Para ello, tendremos que también tener información sobre el dato de maniobras no OK. De tal manera que la suma de ambas sí nos dé una idea clara de lo que ha hecho el robot. Por ejemplo, 15,000 OK y 5,000 no OK serían 20,000 maniobras. En este caso, sí podríamos decidir cambiar la junta porque ya he hecho más de las 15,000. Es suficiente, aunque siempre se puede ir enriqueciendo esta información.</p>
						<p>Por ejemplo, si nuestra intención es hacer un estudio de la productividad de la máquina, el saber que la máquina ha hecho 15,000 maniobras no nos da una idea de la productividad. Esas 15,000 maniobras las puede hacer en un minuto, en una hora, en un día. No tenemos la tasa de productividad de la máquina real. Entonces, aquí quizás haría falta también otro dato adicional, que es el tiempo que lleva en producción.</p>
						<p>En fin, estos datos por sí solos, de forma independiente, pueden servir de ayuda o no, dependiendo de lo que se esté buscando. Pero cuanto más valiosos son, es cuando se pueden mezclar con otros datos para obtener informaciones más elaboradas.</p>
						<p>La aplicación propuesta propone estos datos. Son muy pocos datos por robot y luego algunos que son más genéricos, como por ejemplo los ítems perdidos por la cinta de recogida o los perdidos por la de entrega. ¿Cómo funciona esto? Bueno, en principio, estos datos se suelen dejar preparados en lo que es la parte superior de la máquina, el nivel superior, el Main Machine. Aquí, en esta sección que se llama OpcUA, si nos dirigimos a esta sección, vemos que cogemos variables de la máquina. Aquí recordemos, se utiliza la variable g_stPD3 y estos datos los cocinamos de alguna manera, los dejamos preparados para subirlos a la capa superior, la capa Gateway, donde ya serán procesados y enviados a un software basado en nube.</p>
						<p>Si nos fijamos, vamos cogiendo datos de la máquina, algunos directamente ya son utilizables. Se asignan a unas nuevas variables que se han creado para ser subidas a la capa Gateway vía OpcUA. Otros se convierten de tipo de variable y otros ya están un poco más cocinados. Por ejemplo, en este caso de aquí, el estado del robot 1. En cada uno de los bits vemos que el estado del robot 1 es un Word, y cada uno de los bits coge información de bits de la máquina, incluso algunos se hacen algún tipo de operación.</p>
						<p>Entonces, estas variables, que son las que se van a subir, básicamente, estas están definidas en la carpeta 3 dentro de este bloque de variables globales. Esto es para que sean fácilmente reconocibles. Serían estas de aquí. Estas son las que realmente se van a subir a la capa Gateway vía OpcUA. ¿Cómo se suben? Bien, se suben a través de este otro objeto que es el "Symbol Configuration". Aquí, doble clic y se marcan para ser subidas, simplemente marcándolas, estas variables serán comunicadas hacia el exterior. Y, por supuesto, no nos hemos de olvidar de marcar aquí que queremos activar el servidor OpcUA.</p>
						<p>Bien hecho esto, estas variables ya se publican hacia un elemento hardware, que en este caso es un PC Industrial. Voy a utilizar el mismo PC que estoy utilizando para ver el código de la aplicación, donde se encuentra en este caso concreto. Hay muchas formas de hacerlo en un entorno de desarrollo que se llama Node-RED. Entonces, si nos vamos a Node-RED, aquí vemos el programa. Vemos que estas variables se leen a través de una serie de nodos que vienen dentro del lenguaje Node-RED y se leen de dos formas distintas. Se leen cíclicamente. En este caso, por ejemplo, los datos del robot 1 se leerían cada 30 segundos. Y luego también hay unas pocas variables que se leen por suscripción. Es decir, cuando su valor cambia, lo que serían los estados, en este ejemplo, que también se incluye dentro de la memoria técnica. Se han empleado ambos métodos para que se vean claras las dos posibilidades.</p>
						<p>Hay que tener en cuenta que hasta aquí el coste de subir datos hasta la capa Gateway es gratuito. No importa subir muchos o pocos, pero a partir de este punto, cuando se intenta subir datos a un software basado en nube, estas subidas cuestan un dinero por variable. Cada vez que subimos una variable, sea del tipo que sea, sea booleano o sea real, da igual, cuesta un coste. Por tanto, hay que estudiar muy bien qué variables vamos a subir y cada cuánto vamos a subirlas. Subir todas estas variables cada 30 segundos, dependiendo de lo que queramos conseguir, siempre puede ser aceptable o puede ser excesivamente caro para el objetivo que se pretende. En estos casos, siempre sería mejor utilizar la suscripción. La suscripción también hay que utilizarla con cierta inteligencia. No es lo mismo, por ejemplo, subir por suscripción un valor que fluctúa constantemente, como el consumo de un motor, que estaría constantemente modificando su valor y, por tanto, constantemente siendo subido a la nube, que, por ejemplo, el modo de trabajo o el número de averías, que no suele cambiar muy frecuentemente.</p>
						<p>Bien, de esta manera subimos los dos, juntamos la información, la compactamos en el formato que entiende el software basado en nube y aquí se envía HTTP, utilizando el protocolo HTTP hacia la nube. ¿Por qué? Porque el software basado en nube acepta solamente este formato. Aquí, en la ventana de debug, vemos lo que se está intentando subir. Aquí, en este payload, lo que hacemos es analizar la respuesta de este nodo y la mostramos aquí. Así vemos cómo se está subiendo la información empaquetada hacia el software basado en nube.</p>
						<p>Y bien, para acceder al software basado en nube, venimos aquí, abrimos una pestaña en Google, activamos el link que ya tengo preparado. Selecciono este, que sería la pantalla principal del software basado en nube, donde podemos ver todas las máquinas que tenemos conectadas. Y esta en concreto estaría aquí, correspondería al proyecto final de master. Iríamos a monitor y aquí tendríamos el dashboard principal. Esto funciona a través de widgets. Cada información mostrada aquí se obtiene o se representa a través de un widget.</p>
						<p>Lo más importante de todo esto, estaríamos hablando mucho tiempo sobre este software, vamos a hablar de la parte elemental. Lo más importante son los valores leídos. Si venimos aquí, vemos que tenemos valores obtenidos de una calculadora interna, es decir, calculados en la nube, y otros que son los que están leídos de la capa inferior, la capa Gateway.</p>
						<p>Vale, a través de los valores leídos es posible extraer más información haciendo cálculos entre ellos. Por eso también a veces es importante, cuando se diseña el sistema, subir solamente datos de tipo básico, suficientes para extraer información, pero que combinados con otros datos nos puedan ofrecer más información aún. Estos nuevos datos los calcularías en la nube para evitarnos el coste de subirlos.</p>
						<p>¿Cómo se calculan? Bueno, los cálculos normalmente suelen ser muy sencillos. Los cálculos no requieren programación. Venimos aquí en Calculator; en esta pestaña hay varias posibilidades. En este caso concreto, por ejemplo, esta variable, la R1_OEE, pues venimos aquí a editar y veremos cómo se hace el cálculo. Simplemente añadimos aquí, en el listado de variables, las que queremos utilizar de la lista que hemos visto anteriormente y, a través de una serie de operadores matemáticos, nos montamos nuestra fórmula y obtenemos un resultado. Este nuevo valor, esta nueva fórmula, recibe un nombre, como si fuera un nombre de una variable, y lo podemos utilizar dentro de nuestros widgets.</p>
						<p>Como ejemplo, se propone una aplicación en un entorno basado en tres dashboards: uno principal que nos da una información general del sistema; otro que nos indica, con todos los datos cocinados y en bruto, una serie de información para extraer el OEE de cada uno de los robots. De esta forma, podemos ver formas de mejorar la productividad de cada uno de ellos. Por ejemplo, en este caso, veríamos que el robot 4 tiene una productividad ligeramente inferior a la de los demás. Podemos estudiar el porqué, y aquí abajo tendríamos los datos básicos, los KPI que forman el OEE: los indicadores de proceso, disponibilidad, rendimiento y calidad. Estos multiplicados entre sí forman el OEE, para comprobar, por ejemplo, cuál es el elemento a mejorar.</p>
						<p>En este caso, ya vemos que la disponibilidad del cuarto robot es bastante inferior que el resto, mientras que el resto de indicadores son bastante similares. Por tanto, nos centraríamos más en la disponibilidad del cuarto robot que en la calidad. La calidad, por ejemplo, aquí ya vemos que el cuarto robot es el que tiene la peor calidad, pero estamos hablando de 53 errores frente a 9213 no errores. Por tanto, en este caso, aunque el robot 4 tiene una calidad menor, no merece la pena invertir muchos recursos en mejorarla, porque es insignificante.</p>
						<p>Con el rendimiento pasa igual. Es cierto que todos los robots tienen un rendimiento inferior a la producción teórica, pero en proporción es más o menos el mismo tanto para el robot 1, el robot 2, el robot 3, o el robot 4. También es cierto que para el robot 4 la producción teórica es inferior que la teórica del robot 3. Por tanto, es normal que la producción real también sea inferior, pero en proporción son iguales. Por lo tanto, en cuanto a rendimiento tampoco hay que invertir muchos recursos en su mejora. Donde realmente hay que mejorar es en la disponibilidad.</p>
						<p>Otro dashboard que tenemos es el de la productividad. Aquí podemos ver, por ejemplo, datos históricos sobre los ciclos por minuto de los robots 2, 3 y 4. Vemos que, aunque fluctúan con el tiempo, son similares. Contrastamos esta información con los productos perdidos por las cintas. Vemos que el producto perdido en las cintas de "Place" es solamente uno, mientras que en las cintas de recogida va subiendo con el tiempo hasta llegar al estado actual que serían 636. Esto quiere decir que, de alguna manera, la cinta de recogida está alimentando demasiados ítems, o los cuatro robots en su conjunto no son capaces de procesar todos los ítems que conlleva la cinta. Por tanto, quizás sería buena idea subir la velocidad de todos los robots o bajar la velocidad de la cinta de recogida, porque no estamos procesando todos los ítems que están circulando por ahí.</p>
						<p>En mantenimiento, si nos interesa realmente mejorar el mantenimiento, lo que estamos viendo aquí son los desplazamientos, esos serían datos brutos: el desplazamiento de cada uno de los robots. Vemos que el robot 4 apenas se desplaza. De alguna manera, el robot 4 o no le llegan piezas, o tiene algún problema de lentitud que no le hace procesar correctamente los ítems que le están llegando. También, el tiempo de producción del robot 4 es inferior al del resto. Esto quiere decir que, efectivamente, no es un problema de velocidad, sino de que realmente no se está moviendo el robot. Es decir, de alguna manera ya no le están llegando piezas al robot número 4, probablemente porque el robot 1, 2 y 3 están absorbiendo toda la producción, mientras que el 4 no está absorbiendo toda la producción.</p>
						<p>En el último gráfico vemos las maniobras. Lo mismo, vemos que las maniobras realizadas por el cuarto robot no son tan elevadas como las realizadas por los anteriores robots. De hecho, de forma muy ligera, vemos que el robot número 1 es el que más trabaja, el robot número 2 trabaja un pelín menos y el robot número 3 trabaja ya un pelín menos, pero el 4 ya es exagerado; ya no le llegan ítems. Por tanto, tendríamos que quizás buscar métodos para equilibrar el reparto de carga entre los robots.</p>
						<p>Para concluir este vídeo, con datos muy simples podemos realizar estudios más o menos elaborados que nos permitan extraer información a largo plazo para mejorar la producción y también mejorar nuestros planes de mantenimiento. No obstante, cada aplicación es un mundo, y lo que es la plataforma de desarrollo de aplicaciones multirobot incluye una serie de datos, pero puede ser que sea necesario el uso de otros datos distintos. O a lo mejor con los datos que se proponen simplemente utilizar dos o tres de ellos. Por ejemplo, si quisiéramos crear un modelo de negocio basado en servitización, únicamente necesitaríamos un dato: el número de maniobras.</p>
						<p>¿Qué podemos hacer? Podemos, por ejemplo, proponer a nuestros clientes, si somos un fabricante de maquinaria, que les vamos a entregar la máquina, la línea robotizada, totalmente gratuita, y solo les vamos a cobrar un tanto por ciento por producto fabricado. De esta manera, él se ahorra la gran inversión de comprar una línea robotizada, que a lo mejor solo necesita para la presente campaña. A cambio, él tendrá que darnos un porcentaje de cada pieza fabricada. Pero, por otro lado, él también podrá sacar más margen por cada pieza fabricada porque no tendrá que amortizar esta línea. Por tanto, él sale ganando, y nosotros como fabricantes de maquinaria también saldríamos ganando a la larga. Recuperaríamos la línea y se la podríamos vender a otro cliente. Eso sería un posible modelo de negocio nuevo. No todo el mundo puede permitirse la inversión de comprar una línea entera, a veces bien para tenerla en funcionamiento varios años, 3, 4 o 5 años, o a veces simplemente la necesita para una campaña en concreto o para absorber una punta de trabajo concreta. Muchas veces se suele hacer sobreexplotar las máquinas ya presentes por no comprar una nueva que no justifica el coste para una sola campaña.</p>
						<p>En fin, las funcionalidades IoT permitirían estos nuevos modelos de negocio, así como, por ejemplo, mejores o más eficientes técnicas de mantenimiento o incluso estudios de la máquina. Todo depende de lo que se busque con estas funcionalidades nuevas.</p>					
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
					<p><strong>Objetivos y Utilización de Funcionalidades IoT:</strong> Las funcionalidades IoT en una plataforma de desarrollo de aplicaciones multirobot deben alinearse con objetivos específicos, como mejorar la productividad, desarrollar planes de mantenimiento eficientes o crear nuevos modelos de negocio. La utilidad de los datos obtenidos depende de los objetivos planteados, y estos datos deben ser combinados adecuadamente para ofrecer información útil.</p>
					<p><strong>Datos Requeridos para Análisis Eficaz:</strong> La calidad del análisis depende de la variedad y precisión de los datos recolectados. Por ejemplo, para un plan de mantenimiento, no solo es importante el número de maniobras OK, sino también el número de maniobras no OK para extraer el porcentaje de efectividad. Para evaluar la productividad, es crucial combinar el número de maniobras con el tiempo de producción. Solo al combinar estos datos se puede obtener una visión completa y precisa.</p>
					<p><strong>Subida y Procesamiento de Datos:</strong> La subida de datos a una capa Gateway y su procesamiento en la nube deben ser gestionados cuidadosamente para optimizar costos. La recopilación cíclica y por suscripción de datos debe ser equilibrada para evitar costos excesivos. Además, el procesamiento en la nube permite realizar cálculos adicionales para generar información más elaborada a partir de datos básicos ahorrando costes al evitar realizar estos cálculos en la capa OT y luego subirlos a la nube.</p>
					<p><strong>Aplicaciones y Modelos de Negocio:</strong> Las funcionalidades IoT permiten no solo mejorar el mantenimiento y la productividad, sino también explorar nuevos modelos de negocio, como la servitización. Por ejemplo, un modelo de negocio basado en cobrar por el uso de una línea robotizada en lugar de venderla, puede ofrecer ventajas tanto para el fabricante como para el cliente, facilitando la inversión en maquinaria de alta tecnología.</p>
				</div>	
			</div>

			<!-- Capítulo 9: Ajustes trayectoria modo automático -->
			<div class="capitulo-container" id="capitulo9" style="display:none;">
				<iframe 
					src="https://www.youtube.com/embed/V773qxzeBNo?rel=0" 
					frameborder="0" 
					allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
					allowfullscreen 
					aria-label="Vídeo que describe los diversos parámetros existentes para configurar la trayectoria utilizada en el modo automático."> 
				</iframe>

				<div class="transcripcion-container">
					<div class="transcripcion-header">
						<span class="transcripcion-icon">▶</span>
						<span class="transcripcion-text">Transcripción</span>
					</div>	
					<div class="transcripcion-content">
						<p>En este vídeo se describirán las opciones existentes para configurar la trayectoria que seguirá el robot en modo automático. Para ello, nos dirigiremos al panel de configuración y a la sección donde se encuentran los parámetros relativos al modo automático de trabajo.</p>
						<p>Tal como vemos en este panel, una trayectoria de Pick&Place es básicamente un spline cuya cota superior corresponde con la cota Z de la posición de reposo, y las inferiores con la cota Z de los sistemas de coordenadas empleados por la cinta de entrega y la de recogida. Vamos a utilizar la representación 3D para ver el aspecto de esta trayectoria. Para ello, nos dirigiremos al panel automático y desinhibiremos el robot.</p>
						<p>Vemos a través de la sombra que deja el TCP a lo largo de la trayectoria que esta es efectivamente un spline. Este tipo de movimiento es bastante adecuado para suavizar la mecánica y reducir los desgastes producidos por aceleraciones bruscas y cambios repentinos de sentido. Sin embargo, tiene algunas limitaciones.</p>
						<p>La primera es que, tal como está definido, no se tiene en cuenta la altura del producto o del ítem. Por lo tanto, al dirigirse hasta la cota Z del sistema de coordenadas empleado por las cintas, es decir, hacia la superficie de las cintas, podemos impactar contra el producto. Para evitarlo, tenemos un parámetro que sería este de aquí: "altura herramienta". Si nos fijamos, el objeto que representa el plato del robot se ilumina en rojo cuando hay un impacto contra otro objeto gráfico, en este caso, el ítem.</p>
						<p>Si aquí indicamos que la altura del ítem es de 20 mm, veremos que esta situación cambia y ahora mismo ya nos ilumina en rojo porque estamos dejando el producto a una altura de 20 mm de la superficie de la cinta.</p>
						<p>Otra desventaja de este tipo de movimiento curvo es que, en algunas situaciones, puede no ser conveniente. Por ejemplo, puede hacer que el producto roce con la cinta cuando nos estamos aproximando, o si estamos entregando el producto dentro de una caja, los brazos podrían impactar contra las paredes de esta caja. Para evitarlo, tenemos el parámetro "altura obstáculo". Podemos definir una altura obstáculo para la recogida, por ejemplo, 50 mm, y para la entrega, por ejemplo, 150 mm si tenemos que entregar en una caja que mide 150 mm de alto.</p>
						<p>Vemos que la trayectoria automáticamente se ha modificado. Esta curva se ha deformado para incluir una sección lineal a su inicio y otra también lineal a su fin. Esta sección lineal se ejecuta tanto al entrar a buscar el producto como al retirarse. De esta forma, nos estamos acercando y alejando linealmente perpendicularmente a la cinta, evitando el problema que hemos descrito anteriormente.</p>
						<p>Esto, aunque positivo, tiene una limitación. Y es que no estamos utilizando segmentos extras; estamos utilizando el mismo segmento curvo al que estamos deformando la sección inicial y final. Con lo cual, no podemos definir distintas velocidades en distintas zonas de este segmento. No podemos hacer que la sección lineal tenga una velocidad distinta a la de la curva. Lo máximo que podemos hacer es variar la velocidad a la ida y a la vuelta, pero de toda la trayectoria. Por ejemplo, en la recogida, ya que habitualmente el TCP va sin pieza, podemos hacerlo más rápido, por ejemplo, 600 mm por segundo. Mientras que en la entrega, cuando el robot posee la pieza en la herramienta, puede interesar hacerlo a una velocidad inferior para evitar que acelerones o brusquedades desprendan la pieza de la herramienta.</p>
						<p>Aquí vemos el efecto en la representación 3D. En un sentido vamos muy rápido y en el otro vamos más lento. No obstante, no podemos modificar la velocidad al aproximarnos para coger la pieza ni al aproximarnos para dejarla. Para hacerlo, tenemos otra opción: la de "altura aproximación". Esto sí añade un segmento lineal adicional tanto al inicio como al final de esta trayectoria. Vamos a poner una aproximación de 50 mm tanto para la recogida como para la entrega. Si nos fijamos, veremos que efectivamente los últimos 50 mm se hacen a otra velocidad, tanto al coger como al dejar. Eso sí, solamente cuando me estoy aproximando para coger y cuando me estoy aproximando para dejar, pero no al retirarme.</p>
						<p>Esta velocidad se puede modificar a través de parámetros específicos. En este caso, son 20 mm por segundo, muy bajos para que se note la diferencia. Puede ser que nos interese que al dejar, por ejemplo, imaginemos que estamos dejando no encima de otro producto, sino un poco en el aire, pues no importe tanto esta aproximación. Por tanto, la entrega podemos hacer que se realice a la misma velocidad de aproximación que la trayectoria en este caso.</p>
						<p>Veríamos que toda la trayectoria, incluida la aproximación, se hace a igualdad de velocidad, mientras que el camino de picking de recogida hace toda la trayectoria a 600 mm por segundo, pero los últimos 50 mm se hacen a 20 mm por segundo.</p>
						<p>También tenemos otro parámetro adicional que nos permite crear capas, por eso se llama altura capa. Por ejemplo, ahora tenemos que el objeto mide 20 mm de alto, pero queremos dejarlo en una caja en varias capas. La siguiente capa la podemos dejar a 20 mm más. Nos fijamos y el producto se ha dejado 20 mm por encima del anterior. Podemos ir subiendo a cada viaje. Ahora no nos ha dado tiempo, pero en el siguiente sí. A medida que vamos subiendo, vemos que la retirada se va acortando porque estamos llegando o estamos "comiéndonos" altura de obstáculo. Vamos a ponerle 100. Sin embargo, siempre estamos conservando los 50 mm.</p>
						<p>En este caso, por ejemplo, ahora mismo tenemos una altura de obstáculo de 150 mm y una altura de capa, es decir, todos los objetos miden 100 mm. Como la aproximación es 50 mm, 100 mm + 150 mm serían igual que la altura de obstáculo. Quiere decir que empiezo a aproximar justo en el borde de la caja. Aún así, puedo hacerlo. Vamos a añadirle 120 mm más. Ahora estamos aproximando ya por encima de la zona del obstáculo y 140 mm.</p>
						<p>Ahora tenemos una aproximación de 40 mm por encima del obstáculo y 10 mm dentro del obstáculo. En la última, serían 160 mm. En este caso, la aproximación se sigue dando, lo único que hemos fijado una velocidad muy pequeña. Vamos a añadirle otra vez 20 para que se note. Seguimos aproximándonos, pero la retirada, ya que la altura de la última capa está por encima del borde de la caja, tiene lugar sin sección lineal. Es otra vez un spline. ¿Por qué? Porque la aproximación solo tiene lugar cuando me estoy aproximando para dejar el objeto, pero no al retirarme. Como me estoy retirando por encima de la altura del obstáculo, no tiene lugar ningún segmento lineal.</p>
						<p>De esta forma, con estos parámetros, podemos modificar tanto las velocidades como el aspecto de la trayectoria que sigue el robot, adaptándonos a todo tipo de aplicaciones o, al menos, a las aplicaciones más comunes que nos podemos encontrar con más asiduidad.</p>
					</div>
				</div>
				
				<div class="aspectos-container">
					<h3>Aspectos Clave</h3>
						<p><strong>Forma de la trayectoria:</strong> Se utilizan splines para definir la trayectoria del robot en modo automático, lo cual ayuda a suavizar el movimiento y reducir el desgaste por aceleraciones bruscas y cambios repentinos de dirección.</p>
						<p><strong>Ajuste de Alturas:</strong> Dado que la trayectoria se calcula respecto al centro del plato de montaje de la herramienta, el parámetro "altura de herramienta" es esencial para evitar colisiones con la superficie de las cintas y su ajuste debe tener en cuenta la altura del gripper portando el producto. Además, con el parámetro "altura obstáculo", es posible prevenir que el robot impacte contra elementos como las paredes de una caja durante las operaciones de recogida y entrega.</p>
						<p><strong>Adaptación de la Trayectoria:</strong> La trayectoria se ajustará automáticamente en base a los dos parámetros anteriormente descritos incluyendo secciones lineales al inicio y al final del spline, mejorando la aproximación y retirada del robot, evitando problemas de colisión y movimientos bruscos.</p>
						<p><strong>Ajuste de velocidades:</strong> Es posible definir distintas velocidades para las fases de recogida y entrega, así como para la aproximación y la retirada. Esto ayuda a minimizar el impacto de aceleraciones bruscas y asegura un manejo más delicado del producto.</p>
						<p><strong>Creación de Capas:</strong> El parámetro "altura capa" permite ajustar la altura entre capas de productos cuando se apilan en una caja. Esto permite organizar los productos en diferentes niveles y adaptarse a las dimensiones específicas de la caja.</p>
				</div>	
			</div>
		</section>
		
		<div class="navegacion">
			<button id="prevBtn">Anterior</button>
			<button id="nextBtn">Siguiente</button>
		</div>
    </main>

	<footer id="info">
		<nav aria-label="Enlaces legales">
			<ul>
				<li><a href="nota-legal.html">Nota Legal</a></li>
				<li><a href="politica-privacidad.html">Política de Privacidad</a></li>
			</ul>
		</nav>
		<p>&copy; 2024 Portal de Formación PacDrive. Todos los derechos reservados.</p>
	</footer>
	
    <script src="js/scripts.js"></script>
</body>
</html>
